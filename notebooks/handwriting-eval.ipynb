{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e257d6-ea5a-4fda-892a-7b4a0fcfb518",
   "metadata": {},
   "source": [
    "# Handwriting decoder evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e59640-652c-46ee-bc15-2bd4abbe9105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hh/miniconda3/envs/neuromotor/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from generic_neuromotor_interface.data import make_handwriting_dataset\n",
    "from generic_neuromotor_interface.handwriting_utils import CharacterErrorRates\n",
    "\n",
    "TASK_NAME = \"handwriting\"\n",
    "EMG_DATA_DIR = \"~/emg_data\"  # path to EMG data\n",
    "MODELS_DIR = \"~/emg_models\"  # path to model files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7888a27-a4e0-4d80-9ae5-0bfae2991055",
   "metadata": {},
   "source": [
    "## Download Data Subset and Model Files\n",
    "\n",
    "Before running this notebook, make sure you have downloaded the data (small subset) and model checkpoint.\n",
    "\n",
    "You can do so with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67741eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to README instructions.\n",
    "\n",
    "from generic_neuromotor_interface.scripts.download_data import download_data\n",
    "from generic_neuromotor_interface.scripts.download_models import download_models\n",
    "\n",
    "download_data(TASK_NAME, \"small_subset\", EMG_DATA_DIR)\n",
    "download_models(TASK_NAME, MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c3bfae-0335-4ef1-b182-e28a0d4cac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.expanduser(EMG_DATA_DIR)):\n",
    "    raise FileNotFoundError(f\"The EMG data path does not exist: {EMG_DATA_DIR}\")\n",
    "\n",
    "if not os.path.exists(os.path.expanduser(MODELS_DIR)):\n",
    "    raise FileNotFoundError(f\"The models path does not exist: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3f201-0006-4ec9-a5bf-6a8583a1b450",
   "metadata": {},
   "source": [
    "## Load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5220619a-3102-49bc-8c8b-e608c8bc9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model config\"\"\"\n",
    "\n",
    "config_path = os.path.join(os.path.expanduser(MODELS_DIR), TASK_NAME, \"model_config.yaml\")\n",
    "config = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40cf1f5-d667-44a4-b7bd-3f0b1af56909",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19766bb3-a366-4a9b-a118-f9923d343ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.6 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../emg_models/handwriting/model_checkpoint.ckpt`\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load model checkpoint\"\"\"\n",
    "from generic_neuromotor_interface.lightning import HandwritingModule\n",
    "\n",
    "\n",
    "\n",
    "model_ckpt_path = os.path.join(\n",
    "    os.path.expanduser(MODELS_DIR),\n",
    "    TASK_NAME,\n",
    "    \"model_checkpoint.ckpt\"\n",
    ")\n",
    "\n",
    "model = HandwritingModule.load_from_checkpoint(\n",
    "    model_ckpt_path,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")\n",
    "# model = instantiate(config.lightning_module)\n",
    "# model = model.load_from_checkpoint(\n",
    "#     model_ckpt_path,\n",
    "#     map_location=torch.device(\"cpu\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3b308-0713-419e-9af3-37fa36274909",
   "metadata": {},
   "source": [
    "## Instantiate data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b92765-b05a-49c8-9ac6-ea4a603eaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assemble the data module\"\"\"\n",
    "\n",
    "# Update DataModule config with data path\n",
    "config[\"data_module\"][\"data_location\"] = os.path.expanduser(EMG_DATA_DIR)\n",
    "if \"from_csv\" in config[\"data_module\"][\"data_split\"][\"_target_\"]:\n",
    "    config[\"data_module\"][\"data_split\"][\"csv_filename\"] = os.path.join(\n",
    "        os.path.expanduser(EMG_DATA_DIR),\n",
    "        f\"{TASK_NAME}_corpus.csv\"\n",
    "    )\n",
    "\n",
    "datamodule = instantiate(config[\"data_module\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efd05-02e4-4cdb-9c9d-8ecbd1d1d9f2",
   "metadata": {},
   "source": [
    "## Run inference on one prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef1e0b6-31e5-4106-af02-0e7446f8993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[setup] Loading datasets for split None: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Grab one test prompt\"\"\"\n",
    "\n",
    "test_dataset = make_handwriting_dataset(\n",
    "    dataset_names=[\"handwriting_user_001_dataset_000\"],\n",
    "    data_location=datamodule.data_location,\n",
    "    transform=datamodule.transform,\n",
    "    padding=datamodule.padding,\n",
    "    emg_augmentation=None,\n",
    "    concatenate_prompts=False,\n",
    "    min_duration_s=0.0,\n",
    ")\n",
    "\n",
    "sample = test_dataset[55]  # an arbitrary prompt from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a087ba3b-d0b8-433f-9f97-2260d5b201e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run inference\"\"\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# unpack sample\n",
    "emg = sample[\"emg\"]\n",
    "labels = sample[\"prompts\"]\n",
    "\n",
    "# compute model outputs\n",
    "with torch.no_grad():\n",
    "    emissions, _slice = model(emg.T.unsqueeze(0))\n",
    "\n",
    "    # compute greedy decode outputs\n",
    "    predictions = model.decoder.decode_batch(\n",
    "        emissions=emissions.movedim(0, 1).numpy(),\n",
    "        emission_lengths=model.network.compute_time_downsampling(\n",
    "            emg_lengths=torch.as_tensor([len(emg)]), slc=_slice\n",
    "        )\n",
    "    )\n",
    "\n",
    "predictions = torch.as_tensor(predictions[0])\n",
    "\n",
    "# convert predictions and labels to characters\n",
    "predictions = model.decoder._charset.labels_to_str(predictions)\n",
    "labels = model.decoder._charset.labels_to_str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2abd035-9682-4e8f-b209-7178aa7918eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER of above prompt decode: 21.428571428571427\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluate CER on this prompt\"\"\"\n",
    "\n",
    "metric = CharacterErrorRates()\n",
    "metric.update(\n",
    "    prediction=predictions,\n",
    "    target=labels,\n",
    ")\n",
    "aggregate_metrics = metric.compute()\n",
    "\n",
    "print(\"CER of above prompt decode:\", aggregate_metrics[\"CER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5059309d-d784-4fc2-bfb3-843a39e67986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \t alris ht thanhs \n",
      "Target: \t alright thanks\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print predictions and target\"\"\"\n",
    "\n",
    "print(\n",
    "    f\"Prediction: \\t {predictions} \\n\"\n",
    "    f\"Target: \\t {labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1673e06-9133-486e-9766-64e55f0be4d3",
   "metadata": {},
   "source": [
    "## Evaluate full test set\n",
    "\n",
    "Note that this requires you to have downloaded the full dataset (uncomment the below lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7114195",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to download the full dataset\n",
    "\n",
    "# from generic_neuromotor_interface.scripts.download_data import download_data\n",
    "# download_data(TASK_NAME, \"full_data\", EMG_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0d7e8a-2006-46c8-925c-7253007d5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/hh/miniconda3/envs/neuromotor/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "[setup] Loading datasets for split test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:07<00:00,  7.29it/s]\n",
      "/home/hh/miniconda3/envs/neuromotor/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6419/6419 [38:07<00:00,  2.81it/s]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "        test/CER            30.062541961669922\n",
      "        test/DER            2.7663071155548096\n",
      "        test/IER             8.627671241760254\n",
      "        test/SER            18.668563842773438\n",
      "        test_loss           1.3161078691482544\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"cpu\")\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromotor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
